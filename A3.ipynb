{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "Student Name: Ziyi Jiang  |  Student ID: 634926886  |  UPI: zjia631"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 -- Report\n",
    "\n",
    "###  Data Representation\n",
    "\n",
    "#### Training data\n",
    "The training data (trg.csv) is stored in to two NumPy ndarry:\n",
    "1. A ndarry stores all the instances' classes (string).\n",
    "2. A ndarry stores all the instances' abstractes (string).\n",
    "\n",
    "Reason:\n",
    "1. Sine we use the training data to do the testing, we need to keep the class column.\n",
    "2. We can use the index to find the corresponding abstracte of a class, so the id is not needed.\n",
    "\n",
    "#### Predicting data\n",
    "The predicting data (tst.csv) is also stored in to two NumPy ndarrys:\n",
    "1. A ndarry stores all the instances' ids (string).\n",
    "2. A ndarry stores all the instances' abstractes (string).\n",
    "\n",
    "Reason: <br/>\n",
    "Because tst.csv is the predicting data, we need the ids to record the prediction.\n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "#### Preprocessing method\n",
    "1. all the data is stored as string in NumPy ndarrys.\n",
    "2. The id and classe are stored as one string. For example: \"1\", \"A\".\n",
    "3. The abstracte is splited into substrings by \" \".\n",
    "\n",
    "#### Reason\n",
    "1. The id and class are a single character, so there is no need to split them.\n",
    "2. We need to count the different words in abstractes to calculate the Naive Bayes result, so the abstracte needs to be splited.\n",
    "\n",
    "### Extension\n",
    "The Extension used in this report is Complement Naive Bayes.\n",
    "\n",
    "#### Reason\n",
    "Here is the data of the trg.csv:\n",
    "- Number of each class: {'A': 100, 'B': 1270, 'E': 1729, 'V': 101}\n",
    "- Total word number of each class: {'A': 21181, 'B': 227337, 'E': 305095, 'V': 18211}\n",
    "\n",
    "We can see that both the class number and word number of B and E are significantly more than A and V. This will causes the skewed data bias which makes the Standard Naive Bayes classifier predict more to B and E.\n",
    "\n",
    "However, the Complement Naive Bayes classifier uses the probability of a word occured in other class, which could lower the influence of the skewed data bias and increase the accuracy.\n",
    "\n",
    "#### Implementation\n",
    "The Standard Naive Bayes classifier uses the formula: P(class) * P(abstracte|class) <br/>\n",
    "The Complement Naive Bayes classifier uses the formula: P(class) / P(abstracte|other class) <br/>\n",
    "Due to the 0 probability problem, I use one and total number of unique words as smoothing parameters for P(abstracte|other class) <br/>\n",
    "Due to the underflow problem, the code uses np.log() to record the probabilities. <br/>\n",
    "\n",
    "Detail\n",
    "\n",
    "Firstly, I recorded 6 parameter:\n",
    "1. a list of unique class\n",
    "2. total number of classes\n",
    "3. total number of each class\n",
    "4. total number of unique words\n",
    "5. number of a word in a class\n",
    "6. total number of words in a class\n",
    "\n",
    "Then, I calculate P(class|abstracte) of each class:\n",
    "1. calculate P(class) by using total number of each class / total number of classes\n",
    "2. calculate P(abstracte|other class) by sum all log(P(word|other class)) of each word in the abstracte:\n",
    "    - sum the number of the word in all other classes as a\n",
    "    - sum the total number of words in all other classes as b\n",
    "    - calculate P(word|other class) by using (a + 1) / (b + total number of unique words)\n",
    "3. use log(P(class)) - log(P(abstracte|other class)) to get the log-recorded P(class|abstracte).\n",
    "4. find the maximum log-recorded P(class|abstracte) between all the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 -- Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x, y, test_size=0.2):\n",
    "    n_test = int(test_size * len(x))\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    rng = np.random.default_rng()\n",
    "    perm = rng.permutation(len(x))\n",
    "    test = perm[:n_test]\n",
    "    train = perm[n_test:]\n",
    "    return x[train], x[test], y[train], y[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split(x, k: int = 5):\n",
    "    \"\"\"k-fold cross-validation.\"\"\"\n",
    "    rng = np.random.default_rng()\n",
    "    perm = rng.permutation(len(x))\n",
    "    for split in np.split(perm, k):\n",
    "        rest = perm[~np.isin(perm, split, assume_unique=True)]\n",
    "        yield rest, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(result):\n",
    "    result = np.array(result)\n",
    "    count = sum(result[:, 0] == result[:, 1])\n",
    "    accuracy = count / len(result)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Unique class is stored as self.unique_class.\n",
    "        Total number of classes is stored as self.total_classes_number.\n",
    "        Total number of each class is stored in self.class_number_dict.\n",
    "        Total number of unique words is stored as self.unique_word_number.\n",
    "        Total number of a word in a class is stored in self.class_word_number_dict.\n",
    "        otal number of a word in a class is stored in self.class_total_words_dict.\n",
    "        \"\"\"\n",
    "        self.unique_classes = []\n",
    "        self.total_classes_number = 0\n",
    "        self.class_number_dict = {}\n",
    "        self.unique_word_number = 0\n",
    "        self.class_word_number_dict = {}\n",
    "        self.class_total_words_dict = {}\n",
    "\n",
    "    def fit(self, abstracts, classes):\n",
    "        classes = np.array(classes)\n",
    "        abstracts = np.array(abstracts)\n",
    "        # unique class\n",
    "        self.unique_classes = sorted(set(classes))\n",
    "\n",
    "        # total number of classes\n",
    "        self.total_classes_number = len(classes)\n",
    "\n",
    "        # total number of each class\n",
    "        c, counts = np.unique(classes, return_counts=True)\n",
    "        self.class_number_dict = dict(zip(c, counts))\n",
    "\n",
    "        # total number of unique words\n",
    "        all_text = \"\"\n",
    "        for text in abstracts:\n",
    "            all_text = all_text + text + \" \"\n",
    "        all_text = all_text.split()\n",
    "        unique_word = set(all_text)\n",
    "        self.unique_word_number = len(unique_word)\n",
    "\n",
    "        # total number of a word in a class\n",
    "        self.class_word_number_dict = {}\n",
    "        class_text_dict = {}\n",
    "        for c in self.unique_classes:\n",
    "            class_text_dict[c] = \"\"\n",
    "        for i in range(len(abstracts)):\n",
    "            c = classes[i]\n",
    "            text = abstracts[i]\n",
    "            class_text_dict[c] = class_text_dict[c] + text + \" \"\n",
    "        for c in class_text_dict:\n",
    "            text = np.array(class_text_dict[c].split())\n",
    "            word, counts = np.unique(text, return_counts=True)\n",
    "            self.class_word_number_dict[c] = dict(zip(word, counts))\n",
    "\n",
    "        # total number of words in a class\n",
    "        self.class_total_words_dict = {}\n",
    "        for c in class_text_dict:\n",
    "            text = class_text_dict[c].split()\n",
    "            self.class_total_words_dict[c] = len(text)\n",
    "\n",
    "    def predict(self, abstracts, ids):\n",
    "        result = []\n",
    "        for i in range(len(ids)):\n",
    "            pred_id = ids[i]\n",
    "            pred_abs = abstracts[i].split()\n",
    "            id_result_prob = []\n",
    "            for c in self.unique_classes:\n",
    "                prob_c = np.log(self.class_number_dict[c] / self.total_classes_number)\n",
    "                prob_x = 0\n",
    "                word_number_dict = self.class_word_number_dict[c]\n",
    "                total_words_number = self.class_total_words_dict[c]\n",
    "                for word in pred_abs:\n",
    "                    if word in word_number_dict:\n",
    "                        word_number = word_number_dict[word]\n",
    "                    else:\n",
    "                        word_number = 0\n",
    "                    prob_word = np.log((word_number + 1) / (total_words_number + self.unique_word_number))\n",
    "                    prob_x = prob_x + prob_word\n",
    "                prob = prob_c + prob_x\n",
    "                id_result_prob.append([c, prob])\n",
    "\n",
    "            id_result_prob = sorted(id_result_prob, key=lambda x: x[1])\n",
    "            result.append((pred_id, id_result_prob[-1][0]))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navie Bayes Classifier with Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplementNaiveBayesClassifier:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.unique_classes = []\n",
    "        self.total_classes_number = 0\n",
    "        self.class_number_dict = {}\n",
    "        self.unique_word_number = 0\n",
    "        self.class_word_number_dict = {}\n",
    "        self.class_total_words_dict = {}\n",
    "\n",
    "    def fit(self, abstracts, classes):\n",
    "        classes = np.array(classes)\n",
    "        abstracts = np.array(abstracts)\n",
    "        \n",
    "        self.unique_classes = sorted(set(classes))\n",
    "\n",
    "        self.total_classes_number = len(classes)\n",
    "\n",
    "        c, counts = np.unique(classes, return_counts=True)\n",
    "        self.class_number_dict = dict(zip(c, counts))\n",
    "\n",
    "        all_text = \"\"\n",
    "        for text in abstracts:\n",
    "            all_text = all_text + text + \" \"\n",
    "        all_text = all_text.split()\n",
    "        unique_word = set(all_text)\n",
    "        self.unique_word_number = len(unique_word)\n",
    "\n",
    "        self.class_word_number_dict = {}\n",
    "        class_text_dict = {}\n",
    "        for c in self.unique_classes:\n",
    "            class_text_dict[c] = \"\"\n",
    "        for i in range(len(abstracts)):\n",
    "            c = classes[i]\n",
    "            text = abstracts[i]\n",
    "            class_text_dict[c] = class_text_dict[c] + text + \" \"\n",
    "        for c in class_text_dict:\n",
    "            text = np.array(class_text_dict[c].split())\n",
    "            word, counts = np.unique(text, return_counts=True)\n",
    "            self.class_word_number_dict[c] = dict(zip(word, counts))\n",
    "\n",
    "        self.class_total_words_dict = {}\n",
    "        for c in class_text_dict:\n",
    "            text = class_text_dict[c].split()\n",
    "            self.class_total_words_dict[c] = len(text)\n",
    "\n",
    "    def predict(self, abstracts, ids):\n",
    "        result = []\n",
    "        for i in range(len(ids)):\n",
    "            pred_id = ids[i]\n",
    "            pred_abs = abstracts[i].split()\n",
    "            id_result_prob = []\n",
    "            for c in self.unique_classes:\n",
    "                prob_c = np.log(self.class_number_dict[c] / self.total_classes_number)\n",
    "                prob_x = 0\n",
    "                \"\"\"\n",
    "                Extension\n",
    "                \"\"\"\n",
    "                not_cs = []\n",
    "                word_number_in_ncs = []\n",
    "                total_words_number = 0\n",
    "                for nc in self.unique_classes:\n",
    "                    if nc != c:\n",
    "                        not_cs.append(nc)\n",
    "                        word_number_in_ncs.append(self.class_word_number_dict[nc])\n",
    "                        total_words_number += self.class_total_words_dict[nc]  \n",
    "                for word in pred_abs:\n",
    "                    word_number = 0\n",
    "                    for word_number_dict in word_number_in_ncs:\n",
    "                        if word in word_number_dict:\n",
    "                            word_number += word_number_dict[word]\n",
    "                    prob_word = np.log((word_number + 1) / (total_words_number + self.unique_word_number))\n",
    "                    prob_x = prob_x + prob_word\n",
    "                prob = prob_c - prob_x\n",
    "                id_result_prob.append([c, prob])\n",
    "            id_result_prob = sorted(id_result_prob, key=lambda x: x[1])\n",
    "            result.append((pred_id, id_result_prob[-1][0]))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "train_abstracts = []\n",
    "training_data = np.genfromtxt(\"trg.csv\", delimiter=\",\",  skip_header=1, dtype=str, usecols=(1, 2))\n",
    "classes = training_data[:, 0]\n",
    "train_abstracts = training_data[:, 1]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_abstracts, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94375\n"
     ]
    }
   ],
   "source": [
    "nbc =NaiveBayesClassifier()\n",
    "nbc.fit(train_x, train_y)\n",
    "result = nbc.predict(test_x, test_y)\n",
    "\n",
    "nbc_accuracy = get_accuracy(result)\n",
    "print(nbc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95875\n"
     ]
    }
   ],
   "source": [
    "cnbc =ComplementNaiveBayesClassifier()\n",
    "cnbc.fit(train_x, train_y)\n",
    "result = cnbc.predict(test_x, test_y)\n",
    "\n",
    "cnbc_accuracy = get_accuracy(result)\n",
    "print(cnbc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard mean: 0.9403749999999998\n",
      "Standard std: 0.006047985201701463\n",
      "Complement mean: 0.961375\n",
      "Complement std: 0.004919667163538611\n"
     ]
    }
   ],
   "source": [
    "nbc_scores = []\n",
    "cnbc_scores = []\n",
    "for i in range(10):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(train_abstracts, classes)\n",
    "    \n",
    "    nbc =NaiveBayesClassifier()\n",
    "    nbc.fit(train_x, train_y)\n",
    "    nbc_result = nbc.predict(test_x, test_y)\n",
    "    nbc_accuracy = get_accuracy(nbc_result)\n",
    "    nbc_scores.append(nbc_accuracy)\n",
    "    \n",
    "    cnbc =ComplementNaiveBayesClassifier()\n",
    "    cnbc.fit(train_x, train_y)\n",
    "    cnbc_result = cnbc.predict(test_x, test_y)\n",
    "    cnbc_accuracy = get_accuracy(cnbc_result)\n",
    "    cnbc_scores.append(cnbc_accuracy)\n",
    "\n",
    "print(\"Standard mean:\", np.mean(nbc_scores))\n",
    "print(\"Standard std:\", np.std(nbc_scores))\n",
    "print(\"Complement mean:\", np.mean(cnbc_scores))\n",
    "print(\"Complement std:\", np.std(cnbc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Result of tst.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = []\n",
    "train_abstracts = []\n",
    "training_data = np.genfromtxt(\"trg.csv\", delimiter=\",\",  skip_header=1, dtype=str, usecols=(1, 2))\n",
    "train_classes = training_data[:, 0]\n",
    "train_abstracts = training_data[:, 1]\n",
    "\n",
    "ids = []\n",
    "abstracts = []\n",
    "data = np.genfromtxt(\"tst.csv\", delimiter=\",\",  skip_header=1, dtype=str, usecols=(0, 1))\n",
    "ids = data[:, 0]\n",
    "abstracts = data[:, 1]\n",
    "\n",
    "nbc = NaiveBayesClassifier()\n",
    "nbc.fit(train_abstracts, train_classes)\n",
    "result = nbc.predict(abstracts, ids)\n",
    "\n",
    "f = open(\"nbc_result.csv\", \"a\")\n",
    "f.write(\"id,class\\n\")\n",
    "for r in result:\n",
    "    line = r[0] + \",\" + r[1] + \"\\n\"\n",
    "    f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = []\n",
    "train_abstracts = []\n",
    "training_data = np.genfromtxt(\"trg.csv\", delimiter=\",\",  skip_header=1, dtype=str, usecols=(1, 2))\n",
    "train_classes = training_data[:, 0]\n",
    "train_abstracts = training_data[:, 1]\n",
    "\n",
    "ids = []\n",
    "abstracts = []\n",
    "data = np.genfromtxt(\"tst.csv\", delimiter=\",\",  skip_header=1, dtype=str, usecols=(0, 1))\n",
    "ids = data[:, 0]\n",
    "abstracts = data[:, 1]\n",
    "\n",
    "cnbc = ComplementNaiveBayesClassifier()\n",
    "cnbc.fit(train_abstracts, train_classes)\n",
    "result = cnbc.predict(abstracts, ids)\n",
    "f = open(\"cnbc_result.csv\", \"a\")\n",
    "f.write(\"id,class\\n\")\n",
    "for r in result:\n",
    "    line = r[0] + \",\" + r[1] + \"\\n\"\n",
    "    f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class number: {'A': 100, 'B': 1270, 'E': 1729, 'V': 101}\n",
      "Class word number: {'A': 21181, 'B': 227337, 'E': 305095, 'V': 18211}\n"
     ]
    }
   ],
   "source": [
    "print(\"Class number:\", cnbc.class_number_dict)\n",
    "print(\"Class word number:\", cnbc.class_total_words_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
