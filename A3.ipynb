{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "Student Name: Ziyi Jiang  |  Student ID: 634926886  |  UPI: zjia631"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 -- Report\n",
    "\n",
    "###  1. Data Representation\n",
    "\n",
    "#### Training data\n",
    "The training data (trg.csv) is stored in to two NumPy ndarry:\n",
    "1. A ndarry stores all the instances' classes (string).\n",
    "2. A ndarry stores all the instances' abstractes (string).\n",
    "\n",
    "Reason:\n",
    "1. Sine we use the training data to do the testing, we need to keep the class column.\n",
    "2. We can use the index to find the corresponding abstracte of a class, so the id is not needed.\n",
    "\n",
    "#### Predicting data\n",
    "The predicting data (tst.csv) is also stored in to two NumPy ndarrys:\n",
    "1. A ndarry stores all the instances' ids (string).\n",
    "2. A ndarry stores all the instances' abstractes (string).\n",
    "\n",
    "Reason: <br/>\n",
    "Because tst.csv is the predicting data, we need the ids to record the prediction.\n",
    "\n",
    "#### In Classifier\n",
    "The classifier records 6 data parameter:\n",
    "1. a list of unique class ([\"A\", \"B\", \"E\", \"V\"]) &nbsp;&nbsp;&nbsp; 4. total number of unique words (a dictionary -- {word: number of the word, ...})\n",
    "2. total number of classes (an integer) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5. number of a word in a class (a dictionary of dictionary -- {class{word: number of the word in the class, ...}, ...})\n",
    "3. total number of each class (an integer) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6. total number of words in a class (an integer)\n",
    "\n",
    "\n",
    "### 2. Data Preprocessing\n",
    "\n",
    "#### Preprocessing\n",
    "1. np.genfromtxt is used to read the CSV file, and then the data is split based on different column.\n",
    "2. All the data is stored as string in NumPy ndarrys.\n",
    "3. The individual id and class are stored as one string. For example: \"1\".\n",
    "4. The ids and abstractes of tst.csv are stored. For trg.csv, only the classes and abstractes are stored.\n",
    "5. The abstracte is splited into substrings by \" \".\n",
    "6. The classifier then uses those data to find all needed parameters.\n",
    "\n",
    "#### Reason\n",
    "1. The id and class are a single character, so there is no need to split them.\n",
    "2. For tst.csv we need the id to produce the corresponding prediction, However, we do not need id for trg.csv. We only need to check are the predictions are correct for trg.csv. Hence, the ids of trg.csv is not needed.\n",
    "3. We need to count the different words in abstractes to calculate the Naive Bayes result, so the abstracte needs to be splited.\n",
    "\n",
    "### 3. Extension\n",
    "The Extension used in this report is Complement Naive Bayes.\n",
    "\n",
    "#### Reason\n",
    "Here is the data of the trg.csv:\n",
    "- Number of each class: {'A': 128, 'B': 1602, 'E': 2144, 'V': 126}\n",
    "- Total word number of each class: {'A': 27529, 'B': 285505, 'E': 379088, 'V': 22700}\n",
    "\n",
    "We can see that both the class number and word number of B and E are significantly more than A and V. This will causes the skewed data bias which makes the Standard Naive Bayes classifier predict more to B and E. Because the P(A) and P(V) would be much smaller than P(B) and P(E).\n",
    "\n",
    "However, the Complement Naive Bayes classifier uses the probability of the class divides the probability of a word occured in other class -- P(class) / P(abstracte|other class), which could lower the influence of the skewed data bias and increase the accuracy.\n",
    "\n",
    "For example, if P(abstracte|class1) is lager than P(abstracte|class2) but P(class1) is much smaller tha P(class2). Then, because P(class1) * P(abstracte|class1) < P(class2) * P(abstracte|class2), the Standard Naive Bayes classifier would predict this abstracte as class2. However, the Complement Naive Bayes classifier would calculates P(class1) / P(abstracte|class2) > P(class2) / P(abstracte|class1) and hence assign this abstracte to class1.\n",
    "\n",
    "Therefore, for this dataset, since there is significant skewed data bias, Complement Naive Bayes is a good extension.\n",
    "\n",
    "### 4. Implementation\n",
    "Due to the 0 probability problem, I use 1 and total unique words number as smoothing parameters:<br/>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "P(class|abstracte) = P(class) $\\times$ P(abstracte|class) = P(class) $\\times$ $\\prod_{}^{}$P(word|class) = P(class) $\\times$ $\\prod_{}^{}$$\\frac{\\text{word number } + 1}{\\text{total words number in class } + \\text{ total unique words number}}$\n",
    "\n",
    "Due to the underflow problem, the code uses np.log() to record the probabilities (log-recorded probability):<br/>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "log-recorded P(class|abstracte) = log-recorded P(class) + log-recorded P(abstracte|class) <br/>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "= log-recorded P(class) + $\\sum_{}^{}$log-recorded P(word|class) <br/> \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "= $\\log$$\\frac{\\text{number of the class}}{\\text{total number of classes}}$ + $\\sum_{}^{}$$\\log$$\\frac{\\text{word number } + 1}{\\text{total words number in class } + \\text{ total unique words number}}$\n",
    "\n",
    "#### Standard Naive Bayes Classifier\n",
    "The Standard Naive Bayes classifier uses the formula: P(class|abstracte) = P(class) * P(abstracte|class) <br/>\n",
    "***Detail:*** <br/>\n",
    "Firstly, I recorded 6 parameter:\n",
    "1. a list of unique class &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4. total number of unique words\n",
    "2. total number of classes &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5. number of a word in a class\n",
    "3. total number of each class &nbsp;&nbsp;&nbsp; 6. total number of words in a class\n",
    "\n",
    "Then. I use those parameter to calculate log-recorded P(class|abstracte) of each class:\n",
    "1. calculate log-recorded P(class) by using np.log(number of the class / total number of classes)\n",
    "2. calculate log-recorded P(abstracte|class) by sum all log(P(word|class)) of each word in the abstracte\n",
    "3. use log(P(class)) + log(P(abstracte|class)) to get the log-recorded P(class|abstracte)\n",
    "4. find the class with the maximum log-recorded P(class|abstracte) -- this would be the predicted class\n",
    "\n",
    "#### Complement Naive Bayes Classifier\n",
    "The Complement Naive Bayes classifier uses the formula: P(class|abstracte) = P(class) / P(abstracte|other class) <br/>\n",
    "***Detail:*** <br/>\n",
    "Firstly, I recorded the same 6 parameter as in Standard Naive Bayes classifier.<br/>\n",
    "Then, I calculate P(class|abstracte) of each class:\n",
    "1. the calculation of log-recorded P(class) is the same as in Standard Naive Bayes classifier\n",
    "2. calculate log-recorded P(abstracte|other class) by sum all log(P(word|other class)) of each word in the abstracte:\n",
    "    - a = sum the number of the word in all other classes\n",
    "    - b = sum the total number of words in all other classes\n",
    "    - calculate P(word|other class) by using (a + 1) / (b + total number of unique words)\n",
    "3. use log(P(class)) - log(P(abstracte|other class)) to get the log-recorded P(class|abstracte)\n",
    "4. find the class with the maximum log-recorded P(class|abstracte) -- this would be the predicted class\n",
    "\n",
    "### 5. Result\n",
    "\n",
    "#### Test Method\n",
    "***Split Method*** <br/>\n",
    "The train_test_split() funtion uses numpy.random.default_rng().permutation() to generate random indices within the range of training set size. And, those indices are split based on the split size parameter. Then, the function split the training data based on those indices to training set and test set and returns them.<br/>\n",
    "***Get Accuracy Method*** <br/>\n",
    "The get_accuracy() funtion convert the result into true and false based on the condition (actual class = predicted class). Then, the function counts how many of the result is true by using a sum() function. And use the count / number of result to get and return the accuracy.\n",
    "\n",
    "#### Comparision\n",
    "After ran the two classifiers (Standard Naive Bayes classifier and Complement Naive Bayes classifier) 100 times, and each time uses the same test train split for two classifiers. I got the mean accuracies of two classifier: <br/>\n",
    "Standard mean: 0.9431875000000001 &nbsp;&nbsp;&nbsp;&nbsp; Standard std: 0.008361696523433503 <br/>\n",
    "Complement mean: 0.961475 &nbsp;&nbsp;&nbsp;&nbsp; Complement std: 0.00675550701280074 <br/>\n",
    "We can see that the Complement Naive Bayes classifier's accuracy is about 0.017 more than the Standard Naive Bayes classifier.\n",
    "\n",
    "For the accuracy of tst.csv, Kaggle shows the Standard Naive Bayes classifier's accuracy is 0.95333 and Complement Naive Bayes classifier's accuracy is 97.\n",
    "\n",
    "Therefore, for this dataset, the Complement Naive Bayes classifier is more accurate than the Standard Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 -- Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x, y, test_size=0.2):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    rng = np.random.default_rng()\n",
    "    indices = rng.permutation(len(x))\n",
    "    split_point = int(test_size * len(x))\n",
    "    test_indices = indices[:split_point]\n",
    "    train_indices = indices[split_point:]\n",
    "    return x[train_indices], x[test_indices], y[train_indices], y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(result):\n",
    "    result = np.array(result)\n",
    "    count = sum(result[:, 0] == result[:, 1])\n",
    "    accuracy = count / len(result)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Unique class is stored as self.unique_class.\n",
    "        Total number of classes is stored as self.total_classes_number.\n",
    "        Total number of each class is stored in self.class_number_dict.\n",
    "        Total number of unique words is stored as self.unique_word_number.\n",
    "        Total number of a word in a class is stored in self.class_word_number_dict.\n",
    "        otal number of a word in a class is stored in self.class_total_words_dict.\n",
    "        \"\"\"\n",
    "        self.unique_classes = []\n",
    "        self.total_classes_number = 0\n",
    "        self.class_number_dict = {}\n",
    "        self.unique_word_number = 0\n",
    "        self.class_word_number_dict = {}\n",
    "        self.class_total_words_dict = {}\n",
    "\n",
    "    def fit(self, abstracts, classes):\n",
    "        classes = np.array(classes)\n",
    "        abstracts = np.array(abstracts)\n",
    "        # unique class\n",
    "        self.unique_classes = sorted(set(classes))\n",
    "\n",
    "        # total number of classes\n",
    "        self.total_classes_number = len(classes)\n",
    "\n",
    "        # total number of each class\n",
    "        c, counts = np.unique(classes, return_counts=True)\n",
    "        self.class_number_dict = dict(zip(c, counts))\n",
    "\n",
    "        # total number of unique words\n",
    "        all_text = \"\"\n",
    "        for text in abstracts:\n",
    "            all_text = all_text + text + \" \"\n",
    "        all_text = all_text.split()\n",
    "        unique_word = set(all_text)\n",
    "        self.unique_word_number = len(unique_word)\n",
    "\n",
    "        # total number of a word in a class\n",
    "        self.class_word_number_dict = {}\n",
    "        class_text_dict = {}\n",
    "        for c in self.unique_classes:\n",
    "            class_text_dict[c] = \"\"\n",
    "        for i in range(len(abstracts)):\n",
    "            c = classes[i]\n",
    "            text = abstracts[i]\n",
    "            class_text_dict[c] = class_text_dict[c] + text + \" \"\n",
    "        for c in class_text_dict:\n",
    "            text = np.array(class_text_dict[c].split())\n",
    "            word, counts = np.unique(text, return_counts=True)\n",
    "            self.class_word_number_dict[c] = dict(zip(word, counts))\n",
    "\n",
    "        # total number of words in a class\n",
    "        self.class_total_words_dict = {}\n",
    "        for c in class_text_dict:\n",
    "            text = class_text_dict[c].split()\n",
    "            self.class_total_words_dict[c] = len(text)\n",
    "\n",
    "    def predict(self, abstracts, ids):\n",
    "        result = []\n",
    "        for i in range(len(ids)):\n",
    "            pred_id = ids[i]\n",
    "            pred_abs = abstracts[i].split()\n",
    "            id_result_prob = []\n",
    "            for c in self.unique_classes:\n",
    "                prob_c = np.log(self.class_number_dict[c] / self.total_classes_number)\n",
    "                prob_x = 0\n",
    "                word_number_dict = self.class_word_number_dict[c]\n",
    "                total_words_number = self.class_total_words_dict[c]\n",
    "                for word in pred_abs:\n",
    "                    if word in word_number_dict:\n",
    "                        word_number = word_number_dict[word]\n",
    "                    else:\n",
    "                        word_number = 0\n",
    "                    prob_word = np.log((word_number + 1) / (total_words_number + self.unique_word_number))\n",
    "                    prob_x = prob_x + prob_word\n",
    "                prob = prob_c + prob_x\n",
    "                id_result_prob.append([c, prob])\n",
    "\n",
    "            id_result_prob = sorted(id_result_prob, key=lambda x: x[1])\n",
    "            result.append((pred_id, id_result_prob[-1][0]))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navie Bayes Classifier with Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplementNaiveBayesClassifier:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.unique_classes = []\n",
    "        self.total_classes_number = 0\n",
    "        self.class_number_dict = {}\n",
    "        self.unique_word_number = 0\n",
    "        self.class_word_number_dict = {}\n",
    "        self.class_total_words_dict = {}\n",
    "\n",
    "    def fit(self, abstracts, classes):\n",
    "        classes = np.array(classes)\n",
    "        abstracts = np.array(abstracts)\n",
    "        \n",
    "        self.unique_classes = sorted(set(classes))\n",
    "\n",
    "        self.total_classes_number = len(classes)\n",
    "\n",
    "        c, counts = np.unique(classes, return_counts=True)\n",
    "        self.class_number_dict = dict(zip(c, counts))\n",
    "\n",
    "        all_text = \"\"\n",
    "        for text in abstracts:\n",
    "            all_text = all_text + text + \" \"\n",
    "        all_text = all_text.split()\n",
    "        unique_word = set(all_text)\n",
    "        self.unique_word_number = len(unique_word)\n",
    "\n",
    "        self.class_word_number_dict = {}\n",
    "        class_text_dict = {}\n",
    "        for c in self.unique_classes:\n",
    "            class_text_dict[c] = \"\"\n",
    "        for i in range(len(abstracts)):\n",
    "            c = classes[i]\n",
    "            text = abstracts[i]\n",
    "            class_text_dict[c] = class_text_dict[c] + text + \" \"\n",
    "        for c in class_text_dict:\n",
    "            text = np.array(class_text_dict[c].split())\n",
    "            word, counts = np.unique(text, return_counts=True)\n",
    "            self.class_word_number_dict[c] = dict(zip(word, counts))\n",
    "\n",
    "        self.class_total_words_dict = {}\n",
    "        for c in class_text_dict:\n",
    "            text = class_text_dict[c].split()\n",
    "            self.class_total_words_dict[c] = len(text)\n",
    "\n",
    "    def predict(self, abstracts, ids):\n",
    "        result = []\n",
    "        for i in range(len(ids)):\n",
    "            pred_id = ids[i]\n",
    "            pred_abs = abstracts[i].split()\n",
    "            id_result_prob = []\n",
    "            for c in self.unique_classes:\n",
    "                prob_c = np.log(self.class_number_dict[c] / self.total_classes_number)\n",
    "                prob_x = 0\n",
    "                \"\"\"\n",
    "                Extension\n",
    "                \"\"\"\n",
    "                not_cs = []\n",
    "                word_number_in_ncs = []\n",
    "                total_words_number = 0\n",
    "                for nc in self.unique_classes:\n",
    "                    if nc != c:\n",
    "                        not_cs.append(nc)\n",
    "                        word_number_in_ncs.append(self.class_word_number_dict[nc])\n",
    "                        total_words_number += self.class_total_words_dict[nc]  \n",
    "                for word in pred_abs:\n",
    "                    word_number = 0\n",
    "                    for word_number_dict in word_number_in_ncs:\n",
    "                        if word in word_number_dict:\n",
    "                            word_number += word_number_dict[word]\n",
    "                    prob_word = np.log((word_number + 1) / (total_words_number + self.unique_word_number))\n",
    "                    prob_x = prob_x + prob_word\n",
    "                prob = prob_c - prob_x\n",
    "                id_result_prob.append([c, prob])\n",
    "            id_result_prob = sorted(id_result_prob, key=lambda x: x[1])\n",
    "            result.append((pred_id, id_result_prob[-1][0]))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "train_abstracts = []\n",
    "training_data = np.genfromtxt(\"trg.csv\", delimiter=\",\",  skip_header=1, dtype=str, usecols=(1, 2))\n",
    "classes = training_data[:, 0]\n",
    "train_abstracts = training_data[:, 1]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_abstracts, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95875\n"
     ]
    }
   ],
   "source": [
    "nbc =NaiveBayesClassifier()\n",
    "nbc.fit(train_x, train_y)\n",
    "result = nbc.predict(test_x, test_y)\n",
    "\n",
    "nbc_accuracy = get_accuracy(result)\n",
    "print(nbc_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n"
     ]
    }
   ],
   "source": [
    "cnbc =ComplementNaiveBayesClassifier()\n",
    "cnbc.fit(train_x, train_y)\n",
    "result = cnbc.predict(test_x, test_y)\n",
    "\n",
    "cnbc_accuracy = get_accuracy(result)\n",
    "print(cnbc_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard mean: 0.9431875000000001\n",
      "Standard std: 0.008361696523433503\n",
      "Complement mean: 0.961475\n",
      "Complement std: 0.00675550701280074\n"
     ]
    }
   ],
   "source": [
    "nbc_scores = []\n",
    "cnbc_scores = []\n",
    "for i in range(100):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(train_abstracts, classes)\n",
    "    \n",
    "    nbc =NaiveBayesClassifier()\n",
    "    nbc.fit(train_x, train_y)\n",
    "    nbc_result = nbc.predict(test_x, test_y)\n",
    "    nbc_accuracy = get_accuracy(nbc_result)\n",
    "    nbc_scores.append(nbc_accuracy)\n",
    "    \n",
    "    cnbc =ComplementNaiveBayesClassifier()\n",
    "    cnbc.fit(train_x, train_y)\n",
    "    cnbc_result = cnbc.predict(test_x, test_y)\n",
    "    cnbc_accuracy = get_accuracy(cnbc_result)\n",
    "    cnbc_scores.append(cnbc_accuracy)\n",
    "\n",
    "print(\"Standard mean:\", np.mean(nbc_scores))\n",
    "print(\"Standard std:\", np.std(nbc_scores))\n",
    "print(\"Complement mean:\", np.mean(cnbc_scores))\n",
    "print(\"Complement std:\", np.std(cnbc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Result of tst.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = []\n",
    "train_abstracts = []\n",
    "training_data = np.genfromtxt(\"trg.csv\", delimiter=\",\",  skip_header=1, dtype=str, usecols=(1, 2))\n",
    "train_classes = training_data[:, 0]\n",
    "train_abstracts = training_data[:, 1]\n",
    "\n",
    "ids = []\n",
    "abstracts = []\n",
    "data = np.genfromtxt(\"tst.csv\", delimiter=\",\",  skip_header=1, dtype=str, usecols=(0, 1))\n",
    "ids = data[:, 0]\n",
    "abstracts = data[:, 1]\n",
    "\n",
    "nbc = NaiveBayesClassifier()\n",
    "nbc.fit(train_abstracts, train_classes)\n",
    "result = nbc.predict(abstracts, ids)\n",
    "\n",
    "f = open(\"nbc_result.csv\", \"a\")\n",
    "f.write(\"id,class\\n\")\n",
    "for r in result:\n",
    "    line = r[0] + \",\" + r[1] + \"\\n\"\n",
    "    f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = []\n",
    "train_abstracts = []\n",
    "training_data = np.genfromtxt(\"trg.csv\", delimiter=\",\",  skip_header=1, dtype=str, usecols=(1, 2))\n",
    "train_classes = training_data[:, 0]\n",
    "train_abstracts = training_data[:, 1]\n",
    "\n",
    "ids = []\n",
    "abstracts = []\n",
    "data = np.genfromtxt(\"tst.csv\", delimiter=\",\",  skip_header=1, dtype=str, usecols=(0, 1))\n",
    "ids = data[:, 0]\n",
    "abstracts = data[:, 1]\n",
    "\n",
    "cnbc = ComplementNaiveBayesClassifier()\n",
    "cnbc.fit(train_abstracts, train_classes)\n",
    "result = cnbc.predict(abstracts, ids)\n",
    "f = open(\"cnbc_result.csv\", \"a\")\n",
    "f.write(\"id,class\\n\")\n",
    "for r in result:\n",
    "    line = r[0] + \",\" + r[1] + \"\\n\"\n",
    "    f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'A': 128, 'B': 1602, 'E': 2144, 'V': 126}\n",
    "b = {'A': 27529, 'B': 285505, 'E': 379088, 'V': 22700}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "A: 0.032\n",
      "B: 0.4005\n",
      "E: 0.536\n",
      "V: 0.0315\n"
     ]
    }
   ],
   "source": [
    "print(sum(a.values()))\n",
    "print(\"A:\", a[\"A\"] / sum(a.values()))\n",
    "print(\"B:\", a[\"B\"] / sum(a.values()))\n",
    "print(\"E:\", a[\"E\"] / sum(a.values()))\n",
    "print(\"V:\", a[\"V\"] / sum(a.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714822\n",
      "A: 0.038511685426581725\n",
      "B: 0.39940712513045207\n",
      "E: 0.5303250319659999\n",
      "V: 0.03175615747696629\n"
     ]
    }
   ],
   "source": [
    "print(sum(b.values()))\n",
    "print(\"A:\", b[\"A\"] / sum(b.values()))\n",
    "print(\"B:\", b[\"B\"] / sum(b.values()))\n",
    "print(\"E:\", b[\"E\"] / sum(b.values()))\n",
    "print(\"V:\", b[\"V\"] / sum(b.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
